{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeLabs [Introduction to BeautifulSoup 4 (bs4)](https://eueung.github.io/python/bs4)\n",
    "\n",
    "# Test #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "response = requests.get('http://pyvideo.org/category/50/pycon-us-2014')\n",
    "soup = bs4.BeautifulSoup(response.text)\n",
    "\n",
    "# atags = soup.select('div#video-summary-content a[href^=/video]')\n",
    "links = [a.attrs.get('href') for a in soup.select('div#video-summary-content strong a[href^=/video]')]\n",
    "print links[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import re\n",
    "import requests\n",
    "import argparse\n",
    "\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "root_url = 'http://pyvideo.org'\n",
    "index_url = root_url + '/category/50/pycon-us-2014'\n",
    "\n",
    "def get_video_page_urls():\n",
    "    response = requests.get(index_url)\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    allvids = [a.attrs.get('href') for a in soup.select('div#video-summary-content strong a[href^=/video]')]\n",
    "    return allvids[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_url = 'http://pyvideo.org'\n",
    "video_page_url = '/video/2668/writing-restful-web-services-with-flask'\n",
    "video_data = {}\n",
    "\n",
    "response = requests.get(root_url + video_page_url)\n",
    "soup = bs4.BeautifulSoup(response.text)\n",
    "\n",
    "video_data['title'] = soup.select('div#videobox h3')[0].get_text()\n",
    "video_data['speakers'] = [a.get_text() for a in soup.select('div#sidebar a[href^=/speaker]')]\n",
    "video_data['youtube_url'] = soup.select('div#sidebar a[href^=http://www.youtube.com]')[0].get_text()\n",
    "\n",
    "print video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_data(video_page_url):\n",
    "    video_data = {}\n",
    "    response = requests.get(root_url + video_page_url)\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    \n",
    "    video_data['title'] = soup.select('div#videobox h3')[0].get_text()\n",
    "    video_data['speakers'] = [a.get_text() for a in soup.select('div#sidebar a[href^=/speaker]')]\n",
    "    video_data['youtube_url'] = soup.select('div#sidebar a[href^=http://www.youtube.com]')[0].get_text()\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "\n",
    "response = requests.get('https://www.youtube.com/watch?v=px_vg9Far1Y')\n",
    "soup = bs4.BeautifulSoup(response.text)\n",
    "\n",
    "video_data['views'] = int(re.sub('[^0-9]', '', soup.select('.watch-view-count')[0].get_text()))\n",
    "video_data['likes'] = int(re.sub('[^0-9]', '',soup.select('.like-button-renderer-like-button span.yt-uix-button-content')[0].get_text()))\n",
    "video_data['dislikes'] = int(re.sub('[^0-9]', '',soup.select('.like-button-renderer-dislike-button span.yt-uix-button-content')[0].get_text()))\n",
    "\n",
    "print video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_data(video_page_url):\n",
    "    # ...\n",
    "    # initialize counters\n",
    "    video_data['views'] = 0\n",
    "    video_data['likes'] = 0\n",
    "    video_data['dislikes'] = 0\n",
    "\n",
    "    try:\n",
    "        response = requests.get(video_data['youtube_url'], headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36'})\n",
    "        soup = bs4.BeautifulSoup(response.text)\n",
    "\n",
    "        video_data['views'] = int(re.sub('[^0-9]', '', soup.select('.watch-view-count')[0].get_text()))\n",
    "        video_data['likes'] = int(re.sub('[^0-9]', '',soup.select('.like-button-renderer-like-button span.yt-uix-button-content')[0].get_text()))\n",
    "        video_data['dislikes'] = int(re.sub('[^0-9]', '',soup.select('.like-button-renderer-dislike-button span.yt-uix-button-content')[0].get_text()))\n",
    "\n",
    "    except:\n",
    "        # some or all of the counters could not be scraped\n",
    "        pass\n",
    "\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Show PyCon 2014 video statistics.')\n",
    "    parser.add_argument('--sort', metavar='FIELD', choices=['views', 'likes', 'dislikes'], default='views', help='sort by the specified field. Options are views, likes and dislikes.')\n",
    "    parser.add_argument('--max', metavar='MAX', type=int, help='show the top MAX entries only.')\n",
    "    parser.add_argument('--csv', action='store_true', default=False, help='output the data in CSV format.')\n",
    "    parser.add_argument('--workers', type=int, default=8, help='number of workers to use, 8 by default.')\n",
    "    return parser.parse_args()\n",
    "\n",
    "# ex: python pycon-scraper.py --sort views --max 25 --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_video_stats(options):\n",
    "    pool = Pool(options.workers)\n",
    "    video_page_urls = get_video_page_urls()\n",
    "    results = sorted(pool.map(get_video_data, video_page_urls), key=lambda video: video[options.sort], reverse=True)\n",
    "    print len(results)\n",
    "    \n",
    "    max = options.max\n",
    "    if max is None or max > len(results):\n",
    "        max = len(results)\n",
    "    if options.csv:\n",
    "        print(u'\"title\",\"speakers\", \"views\",\"likes\",\"dislikes\"')\n",
    "    else:\n",
    "        print(u'Views  +1  -1 Title (Speakers)')\n",
    "        \n",
    "    for i in range(max):\n",
    "        if options.csv:\n",
    "            print(u'\"{0}\",\"{1}\",{2},{3},{4}'.format(results[i]['title'], ', '.join(results[i]['speakers']), results[i]['views'], results[i]['likes'], results[i]['dislikes']))\n",
    "        else:\n",
    "            print(u'{0:5d} {1:3d} {2:3d} {3} ({4})'.format(results[i]['views'], results[i]['likes'], results[i]['dislikes'], results[i]['title'], ', '.join(results[i]['speakers'])))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    show_video_stats(parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#References\n",
    "1. [Easy Web Scraping with Python](http://blog.miguelgrinberg.com/post/easy-web-scraping-with-python)\n",
    "1. [Generate statistics about PyCon 2014 videos](https://gist.github.com/miguelgrinberg/5f52ceb565264b1e969a)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
